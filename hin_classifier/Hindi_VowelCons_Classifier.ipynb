{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PyTorch Data Loader Code for Vowel Consonant Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvJPyarzywwS",
        "colab_type": "text"
      },
      "source": [
        "# Read Classifier Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PeozigfFQ850",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "#For converting the dataset to torchvision dataset format\n",
        "class VowelConsonantDataset(Dataset):\n",
        "    def __init__(self, file_path,train=True,transform=None):\n",
        "        self.transform = transform\n",
        "        self.file_path=file_path\n",
        "        self.train=train\n",
        "        self.file_names=[file for _,_,files in os.walk(self.file_path) for file in files]\n",
        "        self.len = len(self.file_names)\n",
        "        if self.train:\n",
        "            self.classes_mapping=self.get_classes()\n",
        "    def __len__(self):\n",
        "        return len(self.file_names)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        file_name=self.file_names[index]\n",
        "        image_data=self.pil_loader(self.file_path+\"/\"+file_name)\n",
        "        if self.transform:\n",
        "            image_data = self.transform(image_data)\n",
        "        if self.train:\n",
        "            file_name_splitted=file_name.split(\"_\")\n",
        "            Y1 = self.classes_mapping[file_name_splitted[0]]\n",
        "            Y2 = self.classes_mapping[file_name_splitted[1]]\n",
        "            z1,z2=torch.zeros(10),torch.zeros(10)\n",
        "            z1[Y1-10],z2[Y2]=1,1\n",
        "            label=torch.stack([z1,z2])\n",
        "\n",
        "            return image_data, label\n",
        "\n",
        "        else:\n",
        "            vow_test_tensor, con_test_tensor = torch.zeros(10,dtype=torch.int64), torch.zeros(10,dtype=torch.int64)\n",
        "            numeric = file_name.split('.')[0]\n",
        "            if len(numeric) < 4:\n",
        "              numeric = '0'*(4-len(numeric))+numeric\n",
        "            if numeric == '10000':\n",
        "              numeric = '9999'\n",
        "            vow_test_tensor[int(numeric[0])] = 1\n",
        "            con_test_tensor[int(numeric[1])] = 1\n",
        "            test_label = torch.stack([vow_test_tensor,con_test_tensor])\n",
        "            return image_data, test_label\n",
        "          \n",
        "    def pil_loader(self,path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "      \n",
        "    def get_classes(self):\n",
        "        classes=[]\n",
        "        for name in self.file_names:\n",
        "            name_splitted=name.split(\"_\")\n",
        "            classes.extend([name_splitted[0],name_splitted[1]])\n",
        "        classes=list(set(classes))\n",
        "        classes_mapping={}\n",
        "        for i,cl in enumerate(sorted(classes)):\n",
        "            classes_mapping[cl]=i\n",
        "        return classes_mapping\n",
        "    "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZgkWhbZzV1T",
        "colab_type": "text"
      },
      "source": [
        "# Imports and Data download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rJJ_MrEVQ_eX",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1Gg9mEGh3W2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import importlib\n",
        "if importlib.util.find_spec('mlflow') is None:\n",
        "  !pip install mlflow\n",
        "import mlflow\n",
        "import mlflow.pytorch"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehfx2lqDBvVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if importlib.util.find_spec('google.colab'):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRx5cA3oByw-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "dcdf5b87-e373-488c-8dab-efd2a4831082"
      },
      "source": [
        "!mkdir -p hin_classifier\n",
        "!unzip -nq \"/content/drive/My Drive/hin_classifier/train.zip\" -d hin_classifier\n",
        "!unzip -nq \"/content/drive/My Drive/hin_classifier/test.zip\" -d hin_classifier"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/sh: 1: unzip: Exec format error\n",
            "/bin/sh: 1: unzip: Exec format error\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmWVDRPnzi8q",
        "colab_type": "text"
      },
      "source": [
        "# Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmIYf267CIy6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa117632-0076-4880-81e6-6cbc1cbf75a0"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZtMz5RkiROn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label_tensor(actual_labels):\n",
        "    return torch.LongTensor([torch.max(labels, dim = -1)[1].item() for labels in actual_labels])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-29aucGx3Tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cumulative_loss(predicted, actual, compute_loss=nn.CrossEntropyLoss()):\n",
        "  actual_reshaped = actual.permute(1,0,2)\n",
        "  vow_labels = label_tensor(actual_reshaped[0])\n",
        "  con_labels = label_tensor(actual_reshaped[1])\n",
        "  vow_labels = vow_labels.to(device)\n",
        "  con_labels = con_labels.to(device)\n",
        "\n",
        "  loss = compute_loss(predicted, vow_labels)\n",
        "  loss += compute_loss(predicted, con_labels)\n",
        "  return loss\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybpnhDMJp6M1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cumulative_correctness(predicted, actual):\n",
        "  correct_value = 0\n",
        "  actual_reshaped = actual.permute(1,0,2)\n",
        "  vow_test = label_tensor(actual_reshaped[0].data).to(device)\n",
        "  con_test = label_tensor(actual_reshaped[1].data).to(device)\n",
        "  correct_value += predicted.eq(vow_test).sum().item()\n",
        "  correct_value += predicted.eq(con_test).sum().item()\n",
        "  return correct_value\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJaO6bec1INt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def standalone_correctness(predicted, actual):\n",
        "  return predicted.eq(actual.data).sum().item()"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8oSBS70zuoz",
        "colab_type": "text"
      },
      "source": [
        "# Train And Test Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLujQRYBjUI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Params(object):\n",
        "    def __init__(self, batch_size, epochs, seed, log_interval):\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.seed = seed\n",
        "        self.log_interval = log_interval\n",
        "\n",
        "max_epochs = 16 if torch.cuda.is_available() else 2\n",
        "args = Params(256, max_epochs, 0, 20)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sobLv8Q-gVeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_data_set,network, optimise, epoch, compute_loss):\n",
        "    \n",
        "  network.train()\n",
        "  for batch_id, data in enumerate(train_data_set):\n",
        "    inputs, labels = data\n",
        "            \n",
        "    optimise.zero_grad()\n",
        "    inputs = inputs.to(device)\n",
        "    outputs = network(inputs)\n",
        "                  \n",
        "    loss = compute_loss(outputs, labels)\n",
        "\n",
        "    loss.backward()\n",
        "    optimise.step()\n",
        "      \n",
        "    if batch_id % args.log_interval == 0:\n",
        "      pos = epoch * len(train_data_set) + batch_id\n",
        "      mlflow.log_metric('train_loss', loss.data.item()/len(inputs)*1000)\n",
        "          \n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.3f}'.format(\n",
        "              epoch, batch_id * len(inputs), len(train_data_set.dataset),\n",
        "              100. * batch_id / len(train_data_set), loss.data.item()))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub_3LZJJ834B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(test_data_set, network, epoch, compute_loss, compute_correctness):\n",
        "    \n",
        "    network.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    confusion_matrix = np.zeros([10, 10])\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for inputs, labels in test_data_set:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = network(inputs)\n",
        "            test_loss += compute_loss(outputs, labels).data.item()\n",
        "            pred = outputs.data.max(1)[1]\n",
        "\n",
        "            correct += compute_correctness(pred,labels)\n",
        "            \n",
        "            for x, y in zip(pred.cpu().numpy(), labels.numpy()):\n",
        "                confusion_matrix[x][y] += 1\n",
        "            \n",
        "        test_loss /= len(test_data_set.dataset)\n",
        "        test_accuracy = 100.0 * correct / len(test_data_set.dataset)\n",
        "        \n",
        "        mlflow.log_metric('test_loss', test_loss*1000)\n",
        "        mlflow.log_metric('test_accuracy', test_accuracy)\n",
        "        \n",
        "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.\n",
        "              format(test_loss, correct, len(test_data_set.dataset), test_accuracy))\n",
        "              \n",
        "        if epoch == args.epochs:\n",
        "            classes = np.arange(10)\n",
        "            fig, ax = plt.subplots()\n",
        "            im = ax.imshow(confusion_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "            ax.figure.colorbar(im, ax=ax)\n",
        "            ax.set(xticks=np.arange(confusion_matrix.shape[1]),\n",
        "                       yticks=np.arange(confusion_matrix.shape[0]),\n",
        "                       xticklabels=classes, yticklabels=classes,\n",
        "                       ylabel='True label',\n",
        "                       xlabel='Predicted label',\n",
        "                       title='Epoch %d' % epoch)\n",
        "            thresh = confusion_matrix.max() / 2.\n",
        "            for i in range(confusion_matrix.shape[0]):\n",
        "                for j in range(confusion_matrix.shape[1]):\n",
        "                    ax.text(j, i, int(confusion_matrix[i, j]),\n",
        "                            ha=\"center\", va=\"center\",\n",
        "                            color=\"white\" if confusion_matrix[i, j] > thresh else \"black\")\n",
        "              \n",
        "            fig.tight_layout()\n",
        "              \n",
        "            image_path = 'images/%s.png' % (expt_id)\n",
        "            plt.savefig(image_path)\n",
        "            mlflow.log_artifact(image_path)\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv0U16cDz9yp",
        "colab_type": "text"
      },
      "source": [
        "# Feed Forward Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsxxftMkSYxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FeedForwardNetwork(nn.Module):\n",
        "    def __init__(self): \n",
        "        super(FeedForwardNetwork, self).__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(12288, 4096),  # 64 x 64 x 3 = 12288\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 16),\n",
        "            nn.BatchNorm1d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 10)\n",
        "        )\n",
        "             \n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-rPHA8u0KUL",
        "colab_type": "text"
      },
      "source": [
        "# Run ffn with classifier data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S-BX7SIgS_bU",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X2cOje6hS_yA",
        "colab": {}
      },
      "source": [
        "full_data = VowelConsonantDataset(\"hin_classifier/train\",train=True,transform=transform)\n",
        "train_size = int(0.9 * len(full_data))\n",
        "test_size = len(full_data) - train_size\n",
        "\n",
        "train_data, validation_data = random_split(full_data, [train_size, test_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=args.batch_size, shuffle=True)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Uzv8q9j63A_L",
        "colab": {}
      },
      "source": [
        "test_data = VowelConsonantDataset(\"hin_classifier/test\",train=False,transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=args.batch_size,shuffle=False)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E596-_UES2m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "e16cc0e0-2632-4f56-c6d9-8c5d099feaca"
      },
      "source": [
        "%%time\n",
        "for epoch in range(args.epochs):\n",
        "  ffn = FeedForwardNetwork().to(device)\n",
        "  train(train_loader,ffn, optim.Adam(ffn.parameters()), epoch,cumulative_loss)\n",
        "  test(test_loader,ffn, epoch,cumulative_loss, cumulative_correctness)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/9000 (0%)]\tLoss: 4.720\n",
            "Train Epoch: 0 [5120/9000 (56%)]\tLoss: 4.614\n",
            "\n",
            "Test set: Average loss: 0.0185, Accuracy: 68682832404704/10000 (686828324047%)\n",
            "\n",
            "Train Epoch: 1 [0/9000 (0%)]\tLoss: 4.757\n",
            "Train Epoch: 1 [5120/9000 (56%)]\tLoss: 4.617\n",
            "\n",
            "Test set: Average loss: 0.0186, Accuracy: 35828643975318/10000 (358286439753%)\n",
            "\n",
            "CPU times: user 3min 31s, sys: 1min 47s, total: 5min 19s\n",
            "Wall time: 3min 8s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAjaQV6lv_zL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if importlib.util.find_spec('google.colab'):\n",
        "  from google.colab import files\n",
        "  files.download('mlruns')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh2NmGh61w2u",
        "colab_type": "text"
      },
      "source": [
        "# MNIST Data Set\n",
        "\n",
        "> *Network*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3xcr9Df1tIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MNISTFFn(nn.Module):\n",
        "    def __init__(self, nH = 32): \n",
        "        super(MNISTFFn, self).__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(784, nH),  # 28 x 28 = 784\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(nH, 10)\n",
        "        )\n",
        "             \n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8npZN4cW3By9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_set = datasets.MNIST('../data', train=True, download=True, \n",
        "                         transform=transform)\n",
        "\n",
        "test_set = datasets.MNIST('../data', train=False, download=True, \n",
        "                         transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=args.batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=args.batch_size, shuffle=False)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24VCxTh-3KXd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "49807e79-3fc4-4927-c9d5-d610bb85e14b"
      },
      "source": [
        "%%time\n",
        "for epoch in range(args.epochs):\n",
        "  mnistffn = MNISTFFn().to(device)\n",
        "  train(train_loader,mnistffn, optim.Adam(mnistffn.parameters()), epoch,nn.CrossEntropyLoss())\n",
        "  test(test_loader,mnistffn, epoch,nn.CrossEntropyLoss(), standalone_correctness)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.386\n",
            "Train Epoch: 0 [5120/60000 (9%)]\tLoss: 1.111\n",
            "Train Epoch: 0 [10240/60000 (17%)]\tLoss: 0.612\n",
            "Train Epoch: 0 [15360/60000 (26%)]\tLoss: 0.531\n",
            "Train Epoch: 0 [20480/60000 (34%)]\tLoss: 0.439\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.301\n",
            "Train Epoch: 0 [30720/60000 (51%)]\tLoss: 0.358\n",
            "Train Epoch: 0 [35840/60000 (60%)]\tLoss: 0.357\n",
            "Train Epoch: 0 [40960/60000 (68%)]\tLoss: 0.367\n",
            "Train Epoch: 0 [46080/60000 (77%)]\tLoss: 0.267\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.393\n",
            "Train Epoch: 0 [56320/60000 (94%)]\tLoss: 0.250\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 9236/10000 (92%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.346\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 1.026\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.642\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.460\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.409\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.346\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.348\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.342\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.315\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.239\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.240\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.253\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 9233/10000 (92%)\n",
            "\n",
            "CPU times: user 43.7 s, sys: 328 ms, total: 44.1 s\n",
            "Wall time: 30.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q543f9u_3epg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}