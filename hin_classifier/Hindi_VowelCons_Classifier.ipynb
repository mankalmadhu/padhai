{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PyTorch Data Loader Code for Vowel Consonant Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PeozigfFQ850",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "#For converting the dataset to torchvision dataset format\n",
        "class VowelConsonantDataset(Dataset):\n",
        "    def __init__(self, file_path,train=True,transform=None):\n",
        "        self.transform = transform\n",
        "        self.file_path=file_path\n",
        "        self.train=train\n",
        "        self.file_names=[file for _,_,files in os.walk(self.file_path) for file in files]\n",
        "        self.len = len(self.file_names)\n",
        "        if self.train:\n",
        "            self.classes_mapping=self.get_classes()\n",
        "    def __len__(self):\n",
        "        return len(self.file_names)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        file_name=self.file_names[index]\n",
        "        image_data=self.pil_loader(self.file_path+\"/\"+file_name)\n",
        "        if self.transform:\n",
        "            image_data = self.transform(image_data)\n",
        "        if self.train:\n",
        "            file_name_splitted=file_name.split(\"_\")\n",
        "            Y1 = self.classes_mapping[file_name_splitted[0]]\n",
        "            Y2 = self.classes_mapping[file_name_splitted[1]]\n",
        "            z1,z2=torch.zeros(10),torch.zeros(10)\n",
        "            z1[Y1-10],z2[Y2]=1,1\n",
        "            label=torch.stack([z1,z2])\n",
        "\n",
        "            return image_data, label\n",
        "\n",
        "        else:\n",
        "            vow_test_tensor, con_test_tensor = torch.zeros(10,dtype=torch.int64), torch.zeros(10,dtype=torch.int64)\n",
        "            numeric = file_name.split('.')[0]\n",
        "            if len(numeric) < 4:\n",
        "              numeric = '0'*(4-len(numeric))+numeric\n",
        "            if numeric == '10000':\n",
        "              numeric = '9999'\n",
        "            vow_test_tensor[int(numeric[0])] = 1\n",
        "            con_test_tensor[int(numeric[1])] = 1\n",
        "            test_label = torch.stack([vow_test_tensor,con_test_tensor])\n",
        "            return image_data, test_label\n",
        "          \n",
        "    def pil_loader(self,path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "      \n",
        "    def get_classes(self):\n",
        "        classes=[]\n",
        "        for name in self.file_names:\n",
        "            name_splitted=name.split(\"_\")\n",
        "            classes.extend([name_splitted[0],name_splitted[1]])\n",
        "        classes=list(set(classes))\n",
        "        classes_mapping={}\n",
        "        for i,cl in enumerate(sorted(classes)):\n",
        "            classes_mapping[cl]=i\n",
        "        return classes_mapping\n",
        "    "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rJJ_MrEVQ_eX",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1Gg9mEGh3W2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import importlib\n",
        "if importlib.util.find_spec('mlflow') is None:\n",
        "  !pip install mlflow\n",
        "import mlflow\n",
        "import mlflow.pytorch"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehfx2lqDBvVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if importlib.util.find_spec('google.colab'):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRx5cA3oByw-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8825bd8f-592f-4be1-b21c-dc4a881ec432"
      },
      "source": [
        "!mkdir -p hin_classifier\n",
        "!unzip -nq \"/content/drive/My Drive/hin_classifier/train.zip\" -d hin_classifier\n",
        "!unzip -nq \"/content/drive/My Drive/hin_classifier/test.zip\" -d hin_classifier"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/sh: 1: unzip: Exec format error\n",
            "/bin/sh: 1: unzip: Exec format error\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmIYf267CIy6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2466c7c-f679-41a8-f7b1-d02ef14d71c0"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S-BX7SIgS_bU",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X2cOje6hS_yA",
        "colab": {}
      },
      "source": [
        "full_data = VowelConsonantDataset(\"hin_classifier/train\",train=True,transform=transform)\n",
        "train_size = int(0.9 * len(full_data))\n",
        "test_size = len(full_data) - train_size\n",
        "\n",
        "train_data, validation_data = random_split(full_data, [train_size, test_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=60, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=60, shuffle=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Uzv8q9j63A_L",
        "colab": {}
      },
      "source": [
        "test_data = VowelConsonantDataset(\"hin_classifier/test\",train=False,transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=60,shuffle=False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZtMz5RkiROn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label_tensor(actual_labels):\n",
        "    return torch.LongTensor([torch.max(labels, dim = -1)[1].item() for labels in actual_labels])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLujQRYBjUI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Params(object):\n",
        "    def __init__(self, batch_size, epochs, seed, log_interval):\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.seed = seed\n",
        "        self.log_interval = log_interval\n",
        "\n",
        "max_epochs = 16 if torch.cuda.is_available() else 4\n",
        "args = Params(256, max_epochs, 0, 20)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsxxftMkSYxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FeedForwardNetwork(nn.Module):\n",
        "    def __init__(self): \n",
        "        super(FeedForwardNetwork, self).__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(12288, 48),  # 64 x 64 x 3 = 12288\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(48, 24),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(24, 10)\n",
        "        )\n",
        "             \n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-29aucGx3Tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cumulative_loss(predicted, actual, compute_loss=nn.CrossEntropyLoss()):\n",
        "  actual_reshaped = actual.permute(1,0,2)\n",
        "  vow_labels = label_tensor(actual_reshaped[0])\n",
        "  con_labels = label_tensor(actual_reshaped[1])\n",
        "  vow_labels = vow_labels.to(device)\n",
        "  con_labels = con_labels.to(device)\n",
        "\n",
        "  loss = compute_loss(predicted, vow_labels)\n",
        "  loss += compute_loss(predicted, con_labels)\n",
        "  return loss\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sobLv8Q-gVeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(network, optimise, epoch, compute_loss):\n",
        "    \n",
        "  network.train()\n",
        "  for batch_id, data in enumerate(train_loader):\n",
        "    inputs, labels = data\n",
        "            \n",
        "    optimise.zero_grad()\n",
        "    inputs = inputs.to(device)\n",
        "    outputs = network(inputs)\n",
        "                  \n",
        "    loss = cumulative_loss(outputs, labels)\n",
        "\n",
        "    loss.backward()\n",
        "    optimise.step()\n",
        "      \n",
        "    if batch_id % args.log_interval == 0:\n",
        "      pos = epoch * len(train_loader) + batch_id\n",
        "      mlflow.log_metric('train_loss', loss.data.item()/len(inputs)*1000)\n",
        "          \n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.3f}'.format(\n",
        "              epoch, batch_id * len(inputs), len(train_loader.dataset),\n",
        "              100. * batch_id / len(train_loader), loss.data.item()))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub_3LZJJ834B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(network, epoch, compute_loss):\n",
        "    \n",
        "    network.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    confusion_matrix = np.zeros([10, 10])\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = network(inputs)\n",
        "            test_loss += compute_loss(outputs, labels).data.item()\n",
        "            pred = outputs.data.max(1)[1]\n",
        "            labels_reshaped = labels.permute(1,0,2)\n",
        "            correct += pred.eq(label_tensor(labels_reshaped[0].data)).sum().item()\n",
        "            correct += pred.eq(label_tensor(labels_reshaped[1].data)).sum().item()\n",
        "\n",
        "            \n",
        "            for x, y in zip(pred.numpy(), labels.numpy()):\n",
        "                confusion_matrix[x][y] += 1\n",
        "            \n",
        "        test_loss /= len(test_loader.dataset)\n",
        "        test_accuracy = 100.0 * correct / len(test_loader.dataset)\n",
        "        \n",
        "        pos = (epoch + 1) * len(train_loader)\n",
        "        mlflow.log_metric('test_loss', test_loss*1000)\n",
        "        mlflow.log_metric('test_accuracy', test_accuracy)\n",
        "        \n",
        "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.\n",
        "              format(test_loss, correct, len(test_loader.dataset), test_accuracy))\n",
        "              \n",
        "        if epoch == args.epochs:\n",
        "            classes = np.arange(10)\n",
        "            fig, ax = plt.subplots()\n",
        "            im = ax.imshow(confusion_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "            ax.figure.colorbar(im, ax=ax)\n",
        "            ax.set(xticks=np.arange(confusion_matrix.shape[1]),\n",
        "                       yticks=np.arange(confusion_matrix.shape[0]),\n",
        "                       xticklabels=classes, yticklabels=classes,\n",
        "                       ylabel='True label',\n",
        "                       xlabel='Predicted label',\n",
        "                       title='Epoch %d' % epoch)\n",
        "            thresh = confusion_matrix.max() / 2.\n",
        "            for i in range(confusion_matrix.shape[0]):\n",
        "                for j in range(confusion_matrix.shape[1]):\n",
        "                    ax.text(j, i, int(confusion_matrix[i, j]),\n",
        "                            ha=\"center\", va=\"center\",\n",
        "                            color=\"white\" if confusion_matrix[i, j] > thresh else \"black\")\n",
        "              \n",
        "            fig.tight_layout()\n",
        "              \n",
        "            image_path = 'images/%s.png' % (expt_id)\n",
        "            plt.savefig(image_path)\n",
        "            mlflow.log_artifact(image_path)\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E596-_UES2m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ee71ff0e-e697-4539-b0e7-23e93e2e4583"
      },
      "source": [
        "%%time\n",
        "for epoch in range(args.epochs):\n",
        "  ffn = FeedForwardNetwork().to(device)\n",
        "  train(ffn, optim.Adam(ffn.parameters()), epoch,cumulative_loss)\n",
        "  test(ffn, epoch,cumulative_loss)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.5408, Accuracy: 1977/10000 (20%)\n",
            "\n",
            "Train Epoch: 0 [0/9000 (0%)]\tLoss: 4.657\n",
            "Train Epoch: 0 [1200/9000 (13%)]\tLoss: 4.641\n",
            "Train Epoch: 0 [2400/9000 (27%)]\tLoss: 4.611\n",
            "Train Epoch: 0 [3600/9000 (40%)]\tLoss: 4.632\n",
            "Train Epoch: 0 [4800/9000 (53%)]\tLoss: 4.592\n",
            "Train Epoch: 0 [6000/9000 (67%)]\tLoss: 4.583\n",
            "Train Epoch: 0 [7200/9000 (80%)]\tLoss: 4.599\n",
            "Train Epoch: 0 [8400/9000 (93%)]\tLoss: 4.584\n",
            "\n",
            "Test set: Average loss: 1.5338, Accuracy: 2145/10000 (21%)\n",
            "\n",
            "Train Epoch: 0 [0/9000 (0%)]\tLoss: 4.637\n",
            "Train Epoch: 0 [1200/9000 (13%)]\tLoss: 4.565\n",
            "Train Epoch: 0 [2400/9000 (27%)]\tLoss: 4.627\n",
            "Train Epoch: 0 [3600/9000 (40%)]\tLoss: 4.600\n",
            "Train Epoch: 0 [4800/9000 (53%)]\tLoss: 4.627\n",
            "Train Epoch: 0 [6000/9000 (67%)]\tLoss: 4.608\n",
            "Train Epoch: 0 [7200/9000 (80%)]\tLoss: 4.635\n",
            "Train Epoch: 0 [8400/9000 (93%)]\tLoss: 4.626\n",
            "Train Epoch: 1 [0/9000 (0%)]\tLoss: 4.622\n",
            "Train Epoch: 1 [1200/9000 (13%)]\tLoss: 4.588\n",
            "Train Epoch: 1 [2400/9000 (27%)]\tLoss: 4.619\n",
            "Train Epoch: 1 [3600/9000 (40%)]\tLoss: 4.638\n",
            "Train Epoch: 1 [4800/9000 (53%)]\tLoss: 4.593\n",
            "Train Epoch: 1 [6000/9000 (67%)]\tLoss: 4.601\n",
            "Train Epoch: 1 [7200/9000 (80%)]\tLoss: 4.609\n",
            "Train Epoch: 1 [8400/9000 (93%)]\tLoss: 4.608\n",
            "\n",
            "Test set: Average loss: 1.5361, Accuracy: 2002/10000 (20%)\n",
            "\n",
            "Train Epoch: 0 [0/9000 (0%)]\tLoss: 4.578\n",
            "Train Epoch: 0 [1200/9000 (13%)]\tLoss: 4.619\n",
            "Train Epoch: 0 [2400/9000 (27%)]\tLoss: 4.605\n",
            "Train Epoch: 0 [3600/9000 (40%)]\tLoss: 4.640\n",
            "Train Epoch: 0 [4800/9000 (53%)]\tLoss: 4.625\n",
            "Train Epoch: 0 [6000/9000 (67%)]\tLoss: 4.613\n",
            "Train Epoch: 0 [7200/9000 (80%)]\tLoss: 4.612\n",
            "Train Epoch: 0 [8400/9000 (93%)]\tLoss: 4.615\n",
            "Train Epoch: 1 [0/9000 (0%)]\tLoss: 4.628\n",
            "Train Epoch: 1 [1200/9000 (13%)]\tLoss: 4.640\n",
            "Train Epoch: 1 [2400/9000 (27%)]\tLoss: 4.605\n",
            "Train Epoch: 1 [3600/9000 (40%)]\tLoss: 4.613\n",
            "Train Epoch: 1 [4800/9000 (53%)]\tLoss: 4.609\n",
            "Train Epoch: 1 [6000/9000 (67%)]\tLoss: 4.605\n",
            "Train Epoch: 1 [7200/9000 (80%)]\tLoss: 4.617\n",
            "Train Epoch: 1 [8400/9000 (93%)]\tLoss: 4.618\n",
            "Train Epoch: 2 [0/9000 (0%)]\tLoss: 4.595\n",
            "Train Epoch: 2 [1200/9000 (13%)]\tLoss: 4.600\n",
            "Train Epoch: 2 [2400/9000 (27%)]\tLoss: 4.603\n",
            "Train Epoch: 2 [3600/9000 (40%)]\tLoss: 4.588\n",
            "Train Epoch: 2 [4800/9000 (53%)]\tLoss: 4.593\n",
            "Train Epoch: 2 [6000/9000 (67%)]\tLoss: 4.590\n",
            "Train Epoch: 2 [7200/9000 (80%)]\tLoss: 4.596\n",
            "Train Epoch: 2 [8400/9000 (93%)]\tLoss: 4.588\n",
            "\n",
            "Test set: Average loss: 1.5332, Accuracy: 2315/10000 (23%)\n",
            "\n",
            "CPU times: user 3min 7s, sys: 32.9 s, total: 3min 40s\n",
            "Wall time: 2min 10s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAjaQV6lv_zL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}