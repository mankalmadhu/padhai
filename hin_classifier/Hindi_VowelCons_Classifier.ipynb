{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PyTorch Data Loader Code for Vowel Consonant Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PeozigfFQ850",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "#For converting the dataset to torchvision dataset format\n",
        "class VowelConsonantDataset(Dataset):\n",
        "    def __init__(self, file_path,train=True,transform=None):\n",
        "        self.transform = transform\n",
        "        self.file_path=file_path\n",
        "        self.train=train\n",
        "        self.file_names=[file for _,_,files in os.walk(self.file_path) for file in files]\n",
        "        self.len = len(self.file_names)\n",
        "        if self.train:\n",
        "            self.classes_mapping=self.get_classes()\n",
        "    def __len__(self):\n",
        "        return len(self.file_names)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        file_name=self.file_names[index]\n",
        "        image_data=self.pil_loader(self.file_path+\"/\"+file_name)\n",
        "        if self.transform:\n",
        "            image_data = self.transform(image_data)\n",
        "        if self.train:\n",
        "            file_name_splitted=file_name.split(\"_\")\n",
        "            Y1 = self.classes_mapping[file_name_splitted[0]]\n",
        "            Y2 = self.classes_mapping[file_name_splitted[1]]\n",
        "            z1,z2=torch.zeros(10),torch.zeros(10)\n",
        "            z1[Y1-10],z2[Y2]=1,1\n",
        "            label=torch.stack([z1,z2])\n",
        "\n",
        "            return image_data, label\n",
        "\n",
        "        else:\n",
        "            return image_data, file_name\n",
        "          \n",
        "    def pil_loader(self,path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "      \n",
        "    def get_classes(self):\n",
        "        classes=[]\n",
        "        for name in self.file_names:\n",
        "            name_splitted=name.split(\"_\")\n",
        "            classes.extend([name_splitted[0],name_splitted[1]])\n",
        "        classes=list(set(classes))\n",
        "        classes_mapping={}\n",
        "        for i,cl in enumerate(sorted(classes)):\n",
        "            classes_mapping[cl]=i\n",
        "        return classes_mapping\n",
        "    "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rJJ_MrEVQ_eX",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1Gg9mEGh3W2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bd894a92-d855-41c9-bbd0-8ca4eb40a36c"
      },
      "source": [
        "import importlib\n",
        "if importlib.util.find_spec('mlflow') is None:\n",
        "  !pip install mlflow\n",
        "import mlflow\n",
        "import mlflow.pytorch"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mlflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/bb/c79f745214c39dd70b8596b8341c4a6f93ec96f6ed7c7a769c6a826d215f/mlflow-1.9.1-py3-none-any.whl (11.9MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0MB 255kB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.3.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from mlflow) (3.10.0)\n",
            "Collecting azure-storage-blob>=12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/3d/31614573e8a197db12d8ab47a7fd813f15bd4a4b5c64e85d23b865de5b9b/azure_storage_blob-12.3.2-py2.py3-none-any.whl (280kB)\n",
            "\u001b[K     |████████████████████████████████| 286kB 35.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from mlflow) (3.13)\n",
            "Collecting sqlalchemy<=1.3.13\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/47/35edeb0f86c0b44934c05d961c893e223ef27e79e1f53b5e6f14820ff553/SQLAlchemy-1.3.13.tar.gz (6.0MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0MB 41.6MB/s \n",
            "\u001b[?25hCollecting gunicorn; platform_system != \"Windows\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/ca/926f7cd3a2014b16870086b2d0fdc84a9e49473c68a8dff8b57f7c156f43/gunicorn-20.0.4-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from mlflow) (2.8.1)\n",
            "Collecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/1e/cabc75a189de0fbb2841d0975243e59bde8b7822bacbb95008ac6fe9ad47/alembic-1.4.2.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 32.1MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.18.5)\n",
            "Collecting querystring-parser\n",
            "  Downloading https://files.pythonhosted.org/packages/4a/fa/f54f5662e0eababf0c49e92fd94bf178888562c0e7b677c8941bbbcd1bd6/querystring_parser-1.2.4.tar.gz\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.1.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from mlflow) (0.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from mlflow) (7.1.2)\n",
            "Collecting gorilla\n",
            "  Downloading https://files.pythonhosted.org/packages/e3/56/5a683944cbfc77e429c6f03c636ca50504a785f60ffae91ddd7f5f7bb520/gorilla-0.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.0.5)\n",
            "Collecting gitpython>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/f9/c315aa88e51fabdc08e91b333cfefb255aff04a2ee96d632c32cb19180c9/GitPython-3.1.3-py3-none-any.whl (451kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 39.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.12.0)\n",
            "Collecting databricks-cli>=0.8.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/57/5c2d6b83cb8753d12f548e89f91037632baa8289677c1b2ab2adf14bf6b2/databricks-cli-0.11.0.tar.gz (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.6/dist-packages (from mlflow) (2.23.0)\n",
            "Collecting docker>=4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/80/4eab8a38ff62c31716d07753980a7c5e6550b61096926384f01e742b4a4b/docker-4.2.1-py2.py3-none-any.whl (143kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 39.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlparse in /usr/local/lib/python3.6/dist-packages (from mlflow) (0.3.1)\n",
            "Collecting prometheus-flask-exporter\n",
            "  Downloading https://files.pythonhosted.org/packages/24/c4/c60d676f33f12f7c64c684bd6a6b82d4605c12b6ff1ca412b8a0449cf08a/prometheus_flask_exporter-0.14.1.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.0->mlflow) (47.3.1)\n",
            "Collecting azure-core<2.0.0,>=1.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/ed/ff9f4669e5b9a78a62fe43b83cc01e9007bbf6e99ec7ab6f73557135099f/azure_core-1.6.0-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 42.6MB/s \n",
            "\u001b[?25hCollecting msrest>=0.6.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/b4/a95380d5199c4785b318038db6d199a203f6970188876b473c00533bc17f/msrest-0.6.17-py2.py3-none-any.whl (84kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.1MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/04/686efee2dcdd25aecf357992e7d9362f443eb182ecd623f882bc9f7a6bba/cryptography-2.9.2-cp35-abi3-manylinux2010_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 38.4MB/s \n",
            "\u001b[?25hCollecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.8MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow) (2.11.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow) (1.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->mlflow) (2018.9)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from databricks-cli>=0.8.7->mlflow) (0.8.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (2.9)\n",
            "Collecting websocket-client>=0.32.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 46.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: prometheus_client in /usr/local/lib/python3.6/dist-packages (from prometheus-flask-exporter->mlflow) (0.8.0)\n",
            "Collecting isodate>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.6.10->azure-storage-blob>=12.0->mlflow) (1.3.0)\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.1.4->azure-storage-blob>=12.0->mlflow) (1.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->mlflow) (1.1.1)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.10->azure-storage-blob>=12.0->mlflow) (3.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.1.4->azure-storage-blob>=12.0->mlflow) (2.20)\n",
            "Building wheels for collected packages: alembic\n",
            "  Building wheel for alembic (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.2-cp36-none-any.whl size=159543 sha256=a110bd85e7374f6604e902bf6980ebc67086edb2adef35f99375085b9e66c8d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/04/83/76023f7a4c14688c0b5c2682a96392cfdd3ee4449eaaa287ef\n",
            "Successfully built alembic\n",
            "Building wheels for collected packages: sqlalchemy, querystring-parser, databricks-cli, prometheus-flask-exporter\n",
            "  Building wheel for sqlalchemy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlalchemy: filename=SQLAlchemy-1.3.13-cp36-cp36m-linux_x86_64.whl size=1217173 sha256=cc352cd25cd2a6fd2d5eb40601fe7e243a8549d0cd6a22831ed2710d0c404a35\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/35/98/4c9cb3fd63d21d5606b972dd70643769745adf60e622467b71\n",
            "  Building wheel for querystring-parser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for querystring-parser: filename=querystring_parser-1.2.4-cp36-none-any.whl size=7079 sha256=171b2c06ceda6c911e3e4f632c9a3a294b8d6b69e7a490e6ad1eff1040fe9159\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/41/34/23ebf5d1089a9aed847951e0ee375426eb4ad0a7079d88d41e\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.11.0-cp36-none-any.whl size=90300 sha256=71ce078e9fc0edd78a20f2e877439aac5f36fa9d967fd40756cf7b46c9d14d10\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/d0/4f/3deeca1f4c47a6aca7c2c6a6e2bf272391565dc86a7718a59b\n",
            "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.14.1-cp36-none-any.whl size=15200 sha256=634f26d53e9b842b38c4986945a8fce3d9ae67710294f844b16c8ff991f3e4e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/36/0f/7b80b9e6cf5fcd81034fe9b5470937f3a2861ec2d47997ffd2\n",
            "Successfully built sqlalchemy querystring-parser databricks-cli prometheus-flask-exporter\n",
            "Installing collected packages: azure-core, isodate, msrest, cryptography, azure-storage-blob, sqlalchemy, gunicorn, Mako, python-editor, alembic, querystring-parser, gorilla, smmap, gitdb, gitpython, databricks-cli, websocket-client, docker, prometheus-flask-exporter, mlflow\n",
            "  Found existing installation: SQLAlchemy 1.3.17\n",
            "    Uninstalling SQLAlchemy-1.3.17:\n",
            "      Successfully uninstalled SQLAlchemy-1.3.17\n",
            "Successfully installed Mako-1.1.3 alembic-1.4.2 azure-core-1.6.0 azure-storage-blob-12.3.2 cryptography-2.9.2 databricks-cli-0.11.0 docker-4.2.1 gitdb-4.0.5 gitpython-3.1.3 gorilla-0.3.0 gunicorn-20.0.4 isodate-0.6.0 mlflow-1.9.1 msrest-0.6.17 prometheus-flask-exporter-0.14.1 python-editor-1.0.4 querystring-parser-1.2.4 smmap-3.0.4 sqlalchemy-1.3.13 websocket-client-0.57.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehfx2lqDBvVL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "cb474ab4-ad5c-4b4f-f69e-75830d981eb2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRx5cA3oByw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p hin_classifier\n",
        "!unzip -nq \"/content/drive/My Drive/hin_classifier/train.zip\" -d hin_classifier\n",
        "!unzip -nq \"/content/drive/My Drive/hin_classifier/test.zip\" -d hin_classifier"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmIYf267CIy6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "161485dc-55d1-4fef-9d0a-b254a9093ee3"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S-BX7SIgS_bU",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X2cOje6hS_yA",
        "colab": {}
      },
      "source": [
        "full_data = VowelConsonantDataset(\"hin_classifier/train\",train=True,transform=transform)\n",
        "train_size = int(0.9 * len(full_data))\n",
        "test_size = len(full_data) - train_size\n",
        "\n",
        "train_data, validation_data = random_split(full_data, [train_size, test_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=60, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=60, shuffle=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Uzv8q9j63A_L",
        "colab": {}
      },
      "source": [
        "test_data = VowelConsonantDataset(\"hin_classifier/test\",train=False,transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=60,shuffle=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZtMz5RkiROn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label_tensor(actual_labels):\n",
        "    return torch.LongTensor([torch.max(labels, dim = -1)[1].item() for labels in actual_labels])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLujQRYBjUI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Params(object):\n",
        "    def __init__(self, batch_size, epochs, seed, log_interval):\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.seed = seed\n",
        "        self.log_interval = log_interval\n",
        "\n",
        "args = Params(256, 4, 0, 20)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsxxftMkSYxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FeedForwardNetwork(nn.Module):\n",
        "    def __init__(self): \n",
        "        super(FeedForwardNetwork, self).__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(12288, 2),  # 64 x 64 x 3 = 12288\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2, 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2, 10)\n",
        "        )\n",
        "             \n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sobLv8Q-gVeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(network, optimise, epochs, compute_loss):\n",
        "    \n",
        "  network.train()\n",
        "  for epoch in range(epochs):   \n",
        "    for batch_id, data in enumerate(train_loader):\n",
        "      inputs, labels = data\n",
        "              \n",
        "      optimise.zero_grad()\n",
        "      inputs = inputs.to(device)\n",
        "      outputs = network(inputs)\n",
        "                    \n",
        "      labels_reshaped = labels.permute(1,0,2)\n",
        "      vow_labels = label_tensor(labels_reshaped[0])\n",
        "      con_labels = label_tensor(labels_reshaped[1])\n",
        "      vow_labels = vow_labels.to(device)\n",
        "      con_labels = con_labels.to(device)\n",
        "\n",
        "      loss = compute_loss(outputs, vow_labels)\n",
        "      loss += compute_loss(outputs, con_labels)\n",
        "\n",
        "\n",
        "      loss.backward()\n",
        "      optimise.step()\n",
        "        \n",
        "      if batch_id % args.log_interval == 0:\n",
        "        pos = epoch * len(train_loader) + batch_id\n",
        "        mlflow.log_metric('train_loss', loss.data.item()/len(inputs)*1000)\n",
        "            \n",
        "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.3f}'.format(\n",
        "                epoch, batch_id * len(inputs), len(train_loader.dataset),\n",
        "                100. * batch_id / len(train_loader), loss.data.item()))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49Rjlg59ENV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_epochs = 16 if torch.cuda.is_available() else 5"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E596-_UES2m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "41827138-e259-4a00-f145-6304c7f623e6"
      },
      "source": [
        "%%time\n",
        "ffn = FeedForwardNetwork().to(device)\n",
        "loss_epoch_arr = []\n",
        "train(ffn, optim.Adam(ffn.parameters()), max_epochs,nn.CrossEntropyLoss())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/9000 (0%)]\tLoss: 4.653\n",
            "Train Epoch: 0 [1200/9000 (13%)]\tLoss: 4.772\n",
            "Train Epoch: 0 [2400/9000 (27%)]\tLoss: 4.662\n",
            "Train Epoch: 0 [3600/9000 (40%)]\tLoss: 4.855\n",
            "Train Epoch: 0 [4800/9000 (53%)]\tLoss: 4.629\n",
            "Train Epoch: 0 [6000/9000 (67%)]\tLoss: 4.704\n",
            "Train Epoch: 0 [7200/9000 (80%)]\tLoss: 4.682\n",
            "Train Epoch: 0 [8400/9000 (93%)]\tLoss: 4.684\n",
            "Train Epoch: 1 [0/9000 (0%)]\tLoss: 4.694\n",
            "Train Epoch: 1 [1200/9000 (13%)]\tLoss: 4.706\n",
            "Train Epoch: 1 [2400/9000 (27%)]\tLoss: 4.684\n",
            "Train Epoch: 1 [3600/9000 (40%)]\tLoss: 4.609\n",
            "Train Epoch: 1 [4800/9000 (53%)]\tLoss: 4.709\n",
            "Train Epoch: 1 [6000/9000 (67%)]\tLoss: 4.637\n",
            "Train Epoch: 1 [7200/9000 (80%)]\tLoss: 4.676\n",
            "Train Epoch: 1 [8400/9000 (93%)]\tLoss: 4.644\n",
            "Train Epoch: 2 [0/9000 (0%)]\tLoss: 4.666\n",
            "Train Epoch: 2 [1200/9000 (13%)]\tLoss: 4.617\n",
            "Train Epoch: 2 [2400/9000 (27%)]\tLoss: 4.610\n",
            "Train Epoch: 2 [3600/9000 (40%)]\tLoss: 4.601\n",
            "Train Epoch: 2 [4800/9000 (53%)]\tLoss: 4.662\n",
            "Train Epoch: 2 [6000/9000 (67%)]\tLoss: 4.611\n",
            "Train Epoch: 2 [7200/9000 (80%)]\tLoss: 4.576\n",
            "Train Epoch: 2 [8400/9000 (93%)]\tLoss: 4.641\n",
            "Train Epoch: 3 [0/9000 (0%)]\tLoss: 4.614\n",
            "Train Epoch: 3 [1200/9000 (13%)]\tLoss: 4.628\n",
            "Train Epoch: 3 [2400/9000 (27%)]\tLoss: 4.659\n",
            "Train Epoch: 3 [3600/9000 (40%)]\tLoss: 4.614\n",
            "Train Epoch: 3 [4800/9000 (53%)]\tLoss: 4.596\n",
            "Train Epoch: 3 [6000/9000 (67%)]\tLoss: 4.601\n",
            "Train Epoch: 3 [7200/9000 (80%)]\tLoss: 4.586\n",
            "Train Epoch: 3 [8400/9000 (93%)]\tLoss: 4.631\n",
            "Train Epoch: 4 [0/9000 (0%)]\tLoss: 4.604\n",
            "Train Epoch: 4 [1200/9000 (13%)]\tLoss: 4.654\n",
            "Train Epoch: 4 [2400/9000 (27%)]\tLoss: 4.616\n",
            "Train Epoch: 4 [3600/9000 (40%)]\tLoss: 4.599\n",
            "Train Epoch: 4 [4800/9000 (53%)]\tLoss: 4.622\n",
            "Train Epoch: 4 [6000/9000 (67%)]\tLoss: 4.600\n",
            "Train Epoch: 4 [7200/9000 (80%)]\tLoss: 4.604\n",
            "Train Epoch: 4 [8400/9000 (93%)]\tLoss: 4.604\n",
            "Train Epoch: 5 [0/9000 (0%)]\tLoss: 4.604\n",
            "Train Epoch: 5 [1200/9000 (13%)]\tLoss: 4.619\n",
            "Train Epoch: 5 [2400/9000 (27%)]\tLoss: 4.625\n",
            "Train Epoch: 5 [3600/9000 (40%)]\tLoss: 4.601\n",
            "Train Epoch: 5 [4800/9000 (53%)]\tLoss: 4.612\n",
            "Train Epoch: 5 [6000/9000 (67%)]\tLoss: 4.627\n",
            "Train Epoch: 5 [7200/9000 (80%)]\tLoss: 4.600\n",
            "Train Epoch: 5 [8400/9000 (93%)]\tLoss: 4.617\n",
            "Train Epoch: 6 [0/9000 (0%)]\tLoss: 4.609\n",
            "Train Epoch: 6 [1200/9000 (13%)]\tLoss: 4.604\n",
            "Train Epoch: 6 [2400/9000 (27%)]\tLoss: 4.605\n",
            "Train Epoch: 6 [3600/9000 (40%)]\tLoss: 4.613\n",
            "Train Epoch: 6 [4800/9000 (53%)]\tLoss: 4.604\n",
            "Train Epoch: 6 [6000/9000 (67%)]\tLoss: 4.595\n",
            "Train Epoch: 6 [7200/9000 (80%)]\tLoss: 4.597\n",
            "Train Epoch: 6 [8400/9000 (93%)]\tLoss: 4.601\n",
            "Train Epoch: 7 [0/9000 (0%)]\tLoss: 4.594\n",
            "Train Epoch: 7 [1200/9000 (13%)]\tLoss: 4.607\n",
            "Train Epoch: 7 [2400/9000 (27%)]\tLoss: 4.599\n",
            "Train Epoch: 7 [3600/9000 (40%)]\tLoss: 4.602\n",
            "Train Epoch: 7 [4800/9000 (53%)]\tLoss: 4.608\n",
            "Train Epoch: 7 [6000/9000 (67%)]\tLoss: 4.607\n",
            "Train Epoch: 7 [7200/9000 (80%)]\tLoss: 4.601\n",
            "Train Epoch: 7 [8400/9000 (93%)]\tLoss: 4.606\n",
            "Train Epoch: 8 [0/9000 (0%)]\tLoss: 4.608\n",
            "Train Epoch: 8 [1200/9000 (13%)]\tLoss: 4.608\n",
            "Train Epoch: 8 [2400/9000 (27%)]\tLoss: 4.606\n",
            "Train Epoch: 8 [3600/9000 (40%)]\tLoss: 4.600\n",
            "Train Epoch: 8 [4800/9000 (53%)]\tLoss: 4.607\n",
            "Train Epoch: 8 [6000/9000 (67%)]\tLoss: 4.606\n",
            "Train Epoch: 8 [7200/9000 (80%)]\tLoss: 4.601\n",
            "Train Epoch: 8 [8400/9000 (93%)]\tLoss: 4.604\n",
            "Train Epoch: 9 [0/9000 (0%)]\tLoss: 4.604\n",
            "Train Epoch: 9 [1200/9000 (13%)]\tLoss: 4.606\n",
            "Train Epoch: 9 [2400/9000 (27%)]\tLoss: 4.608\n",
            "Train Epoch: 9 [3600/9000 (40%)]\tLoss: 4.607\n",
            "Train Epoch: 9 [4800/9000 (53%)]\tLoss: 4.607\n",
            "Train Epoch: 9 [6000/9000 (67%)]\tLoss: 4.607\n",
            "Train Epoch: 9 [7200/9000 (80%)]\tLoss: 4.607\n",
            "Train Epoch: 9 [8400/9000 (93%)]\tLoss: 4.607\n",
            "Train Epoch: 10 [0/9000 (0%)]\tLoss: 4.606\n",
            "Train Epoch: 10 [1200/9000 (13%)]\tLoss: 4.604\n",
            "Train Epoch: 10 [2400/9000 (27%)]\tLoss: 4.602\n",
            "Train Epoch: 10 [3600/9000 (40%)]\tLoss: 4.605\n",
            "Train Epoch: 10 [4800/9000 (53%)]\tLoss: 4.608\n",
            "Train Epoch: 10 [6000/9000 (67%)]\tLoss: 4.606\n",
            "Train Epoch: 10 [7200/9000 (80%)]\tLoss: 4.603\n",
            "Train Epoch: 10 [8400/9000 (93%)]\tLoss: 4.605\n",
            "Train Epoch: 11 [0/9000 (0%)]\tLoss: 4.605\n",
            "Train Epoch: 11 [1200/9000 (13%)]\tLoss: 4.603\n",
            "Train Epoch: 11 [2400/9000 (27%)]\tLoss: 4.607\n",
            "Train Epoch: 11 [3600/9000 (40%)]\tLoss: 4.607\n",
            "Train Epoch: 11 [4800/9000 (53%)]\tLoss: 4.602\n",
            "Train Epoch: 11 [6000/9000 (67%)]\tLoss: 4.604\n",
            "Train Epoch: 11 [7200/9000 (80%)]\tLoss: 4.605\n",
            "Train Epoch: 11 [8400/9000 (93%)]\tLoss: 4.607\n",
            "Train Epoch: 12 [0/9000 (0%)]\tLoss: 4.606\n",
            "Train Epoch: 12 [1200/9000 (13%)]\tLoss: 4.606\n",
            "Train Epoch: 12 [2400/9000 (27%)]\tLoss: 4.606\n",
            "Train Epoch: 12 [3600/9000 (40%)]\tLoss: 4.604\n",
            "Train Epoch: 12 [4800/9000 (53%)]\tLoss: 4.602\n",
            "Train Epoch: 12 [6000/9000 (67%)]\tLoss: 4.603\n",
            "Train Epoch: 12 [7200/9000 (80%)]\tLoss: 4.605\n",
            "Train Epoch: 12 [8400/9000 (93%)]\tLoss: 4.609\n",
            "Train Epoch: 13 [0/9000 (0%)]\tLoss: 4.606\n",
            "Train Epoch: 13 [1200/9000 (13%)]\tLoss: 4.606\n",
            "Train Epoch: 13 [2400/9000 (27%)]\tLoss: 4.604\n",
            "Train Epoch: 13 [3600/9000 (40%)]\tLoss: 4.604\n",
            "Train Epoch: 13 [4800/9000 (53%)]\tLoss: 4.604\n",
            "Train Epoch: 13 [6000/9000 (67%)]\tLoss: 4.606\n",
            "Train Epoch: 13 [7200/9000 (80%)]\tLoss: 4.604\n",
            "Train Epoch: 13 [8400/9000 (93%)]\tLoss: 4.608\n",
            "Train Epoch: 14 [0/9000 (0%)]\tLoss: 4.607\n",
            "Train Epoch: 14 [1200/9000 (13%)]\tLoss: 4.606\n",
            "Train Epoch: 14 [2400/9000 (27%)]\tLoss: 4.606\n",
            "Train Epoch: 14 [3600/9000 (40%)]\tLoss: 4.605\n",
            "Train Epoch: 14 [4800/9000 (53%)]\tLoss: 4.602\n",
            "Train Epoch: 14 [6000/9000 (67%)]\tLoss: 4.607\n",
            "Train Epoch: 14 [7200/9000 (80%)]\tLoss: 4.605\n",
            "Train Epoch: 14 [8400/9000 (93%)]\tLoss: 4.606\n",
            "Train Epoch: 15 [0/9000 (0%)]\tLoss: 4.605\n",
            "Train Epoch: 15 [1200/9000 (13%)]\tLoss: 4.605\n",
            "Train Epoch: 15 [2400/9000 (27%)]\tLoss: 4.607\n",
            "Train Epoch: 15 [3600/9000 (40%)]\tLoss: 4.607\n",
            "Train Epoch: 15 [4800/9000 (53%)]\tLoss: 4.604\n",
            "Train Epoch: 15 [6000/9000 (67%)]\tLoss: 4.602\n",
            "Train Epoch: 15 [7200/9000 (80%)]\tLoss: 4.606\n",
            "Train Epoch: 15 [8400/9000 (93%)]\tLoss: 4.606\n",
            "CPU times: user 1min 40s, sys: 5.3 s, total: 1min 45s\n",
            "Wall time: 1min 45s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR1ZDYnEHkKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}