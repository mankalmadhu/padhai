{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PyTorch Data Loader Code for Vowel Consonant Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PeozigfFQ850",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "#For converting the dataset to torchvision dataset format\n",
        "class VowelConsonantDataset(Dataset):\n",
        "    def __init__(self, file_path,train=True,transform=None):\n",
        "        self.transform = transform\n",
        "        self.file_path=file_path\n",
        "        self.train=train\n",
        "        self.file_names=[file for _,_,files in os.walk(self.file_path) for file in files]\n",
        "        self.len = len(self.file_names)\n",
        "        if self.train:\n",
        "            self.classes_mapping=self.get_classes()\n",
        "    def __len__(self):\n",
        "        return len(self.file_names)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        file_name=self.file_names[index]\n",
        "        image_data=self.pil_loader(self.file_path+\"/\"+file_name)\n",
        "        if self.transform:\n",
        "            image_data = self.transform(image_data)\n",
        "        if self.train:\n",
        "            file_name_splitted=file_name.split(\"_\")\n",
        "            Y1 = self.classes_mapping[file_name_splitted[0]]\n",
        "            Y2 = self.classes_mapping[file_name_splitted[1]]\n",
        "            z1,z2=torch.zeros(10),torch.zeros(10)\n",
        "            z1[Y1-10],z2[Y2]=1,1\n",
        "            label=torch.stack([z1,z2])\n",
        "\n",
        "            return image_data, label\n",
        "\n",
        "        else:\n",
        "            vow_test_tensor, con_test_tensor = torch.zeros(10,dtype=torch.int64), torch.zeros(10,dtype=torch.int64)\n",
        "            numeric = file_name.split('.')[0]\n",
        "            if len(numeric) < 4:\n",
        "              numeric = '0'*(4-len(numeric))+numeric\n",
        "            if numeric == '10000':\n",
        "              numeric = '9999'\n",
        "            vow_test_tensor[int(numeric[0])] = 1\n",
        "            con_test_tensor[int(numeric[1])] = 1\n",
        "            test_label = torch.stack([vow_test_tensor,con_test_tensor])\n",
        "            return image_data, test_label\n",
        "          \n",
        "    def pil_loader(self,path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "      \n",
        "    def get_classes(self):\n",
        "        classes=[]\n",
        "        for name in self.file_names:\n",
        "            name_splitted=name.split(\"_\")\n",
        "            classes.extend([name_splitted[0],name_splitted[1]])\n",
        "        classes=list(set(classes))\n",
        "        classes_mapping={}\n",
        "        for i,cl in enumerate(sorted(classes)):\n",
        "            classes_mapping[cl]=i\n",
        "        return classes_mapping\n",
        "    "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rJJ_MrEVQ_eX",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1Gg9mEGh3W2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import importlib\n",
        "if importlib.util.find_spec('mlflow') is None:\n",
        "  !pip install mlflow\n",
        "import mlflow\n",
        "import mlflow.pytorch"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehfx2lqDBvVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if importlib.util.find_spec('google.colab'):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRx5cA3oByw-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8825bd8f-592f-4be1-b21c-dc4a881ec432"
      },
      "source": [
        "!mkdir -p hin_classifier\n",
        "!unzip -nq \"/content/drive/My Drive/hin_classifier/train.zip\" -d hin_classifier\n",
        "!unzip -nq \"/content/drive/My Drive/hin_classifier/test.zip\" -d hin_classifier"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/sh: 1: unzip: Exec format error\n",
            "/bin/sh: 1: unzip: Exec format error\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmIYf267CIy6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2466c7c-f679-41a8-f7b1-d02ef14d71c0"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S-BX7SIgS_bU",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X2cOje6hS_yA",
        "colab": {}
      },
      "source": [
        "full_data = VowelConsonantDataset(\"hin_classifier/train\",train=True,transform=transform)\n",
        "train_size = int(0.9 * len(full_data))\n",
        "test_size = len(full_data) - train_size\n",
        "\n",
        "train_data, validation_data = random_split(full_data, [train_size, test_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=60, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=60, shuffle=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Uzv8q9j63A_L",
        "colab": {}
      },
      "source": [
        "test_data = VowelConsonantDataset(\"hin_classifier/test\",train=False,transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=60,shuffle=False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZtMz5RkiROn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label_tensor(actual_labels):\n",
        "    return torch.LongTensor([torch.max(labels, dim = -1)[1].item() for labels in actual_labels])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLujQRYBjUI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Params(object):\n",
        "    def __init__(self, batch_size, epochs, seed, log_interval):\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.seed = seed\n",
        "        self.log_interval = log_interval\n",
        "\n",
        "max_epochs = 16 if torch.cuda.is_available() else 4\n",
        "args = Params(256, max_epochs, 0, 20)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsxxftMkSYxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FeedForwardNetwork(nn.Module):\n",
        "    def __init__(self): \n",
        "        super(FeedForwardNetwork, self).__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(12288, 2),  # 64 x 64 x 3 = 12288\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2, 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2, 10)\n",
        "        )\n",
        "             \n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sobLv8Q-gVeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(network, optimise, epochs, compute_loss):\n",
        "    \n",
        "  network.train()\n",
        "  for epoch in range(epochs):   \n",
        "    for batch_id, data in enumerate(train_loader):\n",
        "      inputs, labels = data\n",
        "              \n",
        "      optimise.zero_grad()\n",
        "      inputs = inputs.to(device)\n",
        "      outputs = network(inputs)\n",
        "                    \n",
        "      labels_reshaped = labels.permute(1,0,2)\n",
        "      vow_labels = label_tensor(labels_reshaped[0])\n",
        "      con_labels = label_tensor(labels_reshaped[1])\n",
        "      vow_labels = vow_labels.to(device)\n",
        "      con_labels = con_labels.to(device)\n",
        "\n",
        "      loss = compute_loss(outputs, vow_labels)\n",
        "      loss += compute_loss(outputs, con_labels)\n",
        "\n",
        "\n",
        "      loss.backward()\n",
        "      optimise.step()\n",
        "        \n",
        "      if batch_id % args.log_interval == 0:\n",
        "        pos = epoch * len(train_loader) + batch_id\n",
        "        mlflow.log_metric('train_loss', loss.data.item()/len(inputs)*1000)\n",
        "            \n",
        "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.3f}'.format(\n",
        "                epoch, batch_id * len(inputs), len(train_loader.dataset),\n",
        "                100. * batch_id / len(train_loader), loss.data.item()))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E596-_UES2m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "69c2c612-403b-46fd-80c7-852c7818e1d0"
      },
      "source": [
        "%%time\n",
        "ffn = FeedForwardNetwork().to(device)\n",
        "loss_epoch_arr = []\n",
        "train(ffn, optim.Adam(ffn.parameters()), max_epochs,nn.CrossEntropyLoss())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/9000 (0%)]\tLoss: 4.731\n",
            "Train Epoch: 0 [1200/9000 (13%)]\tLoss: 4.688\n",
            "Train Epoch: 0 [2400/9000 (27%)]\tLoss: 4.846\n",
            "Train Epoch: 0 [3600/9000 (40%)]\tLoss: 4.796\n",
            "Train Epoch: 0 [4800/9000 (53%)]\tLoss: 4.775\n",
            "Train Epoch: 0 [6000/9000 (67%)]\tLoss: 4.589\n",
            "Train Epoch: 0 [7200/9000 (80%)]\tLoss: 4.661\n",
            "Train Epoch: 0 [8400/9000 (93%)]\tLoss: 4.692\n",
            "Train Epoch: 1 [0/9000 (0%)]\tLoss: 4.723\n",
            "Train Epoch: 1 [1200/9000 (13%)]\tLoss: 4.703\n",
            "Train Epoch: 1 [2400/9000 (27%)]\tLoss: 4.678\n",
            "Train Epoch: 1 [3600/9000 (40%)]\tLoss: 4.627\n",
            "Train Epoch: 1 [4800/9000 (53%)]\tLoss: 4.600\n",
            "Train Epoch: 1 [6000/9000 (67%)]\tLoss: 4.652\n",
            "Train Epoch: 1 [7200/9000 (80%)]\tLoss: 4.637\n",
            "Train Epoch: 1 [8400/9000 (93%)]\tLoss: 4.641\n",
            "Train Epoch: 2 [0/9000 (0%)]\tLoss: 4.598\n",
            "Train Epoch: 2 [1200/9000 (13%)]\tLoss: 4.598\n",
            "Train Epoch: 2 [2400/9000 (27%)]\tLoss: 4.636\n",
            "Train Epoch: 2 [3600/9000 (40%)]\tLoss: 4.599\n",
            "Train Epoch: 2 [4800/9000 (53%)]\tLoss: 4.633\n",
            "Train Epoch: 2 [6000/9000 (67%)]\tLoss: 4.627\n",
            "Train Epoch: 2 [7200/9000 (80%)]\tLoss: 4.604\n",
            "Train Epoch: 2 [8400/9000 (93%)]\tLoss: 4.614\n",
            "Train Epoch: 3 [0/9000 (0%)]\tLoss: 4.597\n",
            "Train Epoch: 3 [1200/9000 (13%)]\tLoss: 4.572\n",
            "Train Epoch: 3 [2400/9000 (27%)]\tLoss: 4.640\n",
            "Train Epoch: 3 [3600/9000 (40%)]\tLoss: 4.595\n",
            "Train Epoch: 3 [4800/9000 (53%)]\tLoss: 4.622\n",
            "Train Epoch: 3 [6000/9000 (67%)]\tLoss: 4.584\n",
            "Train Epoch: 3 [7200/9000 (80%)]\tLoss: 4.620\n",
            "Train Epoch: 3 [8400/9000 (93%)]\tLoss: 4.607\n",
            "CPU times: user 48.2 s, sys: 12.4 s, total: 1min\n",
            "Wall time: 45.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KD4QLrGnyH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}